import numpy as np
import psycopg2
from typing import TypedDict, List


class LoginDetails(TypedDict):
    host: str
    port: int
    user: str
    password: str


class QueryDetails(TypedDict):
    database: str
    query: str


class DatabaseConnector(object):
    def __init__(self, login_details: LoginDetails, databasename=None):
        self.connector = psycopg2.connect(
            host=login_details.host,
            port=login_details.port,
            user=login_details.user,
            password=login_details.password,
            dbname=databasename if databasename else "",
        ).cursor()

    def __enter__(self):
        return self.connector

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.connector.close()


def check_connection(login_details: LoginDetails, databasename=None):
    """
    Attempts to connect to a PostgreSQL database and returns True if successful.

    :param login_details: An instance of LoginDetails containing connection parameters.
    :param databasename: Optional. The name of the database to connect to.
    :return: True if the connection is successful, False otherwise.
    """
    try:
        # Connect to the database (or just the server if databasename is None)
        conn = psycopg2.connect(
            host=login_details.host,
            port=login_details.port,
            user=login_details.user,
            password=login_details.password,
            dbname=databasename if databasename else "",
        )

        # If the connection was successful, close it and return True
        print("Login Successful")
        conn.close()
        return True
    except psycopg2.OperationalError as e:
        from project import Main

        Main.show_error("Connection to DB Failed\n" + str(e))
        return False


def get_database_names(login_details: LoginDetails) -> List[str]:
    try:
        with DatabaseConnector(login_details) as cursor:
            query = "SELECT datname FROM pg_database WHERE datistemplate = false;"
            cursor.execute(query)
            database_list = cursor.fetchall()
            database_list = [i[0] for i in database_list]
            return database_list
    except psycopg2.OperationalError as e:
        from project import Main

        Main.show_error(str(e))


def retrieve_query(
    login_details: LoginDetails, querydetails: QueryDetails, explain=True
):
    with DatabaseConnector(login_details, querydetails.database) as cursor:
        if explain:
            query = f"EXPLAIN (ANALYZE, VERBOSE, FORMAT JSON) {str(querydetails.query)}"
        else:
            query = str(querydetails.query)

        try:
            print(querydetails.query.strip())
            cursor.execute(query)
            query_data = cursor.fetchall()
            print(query_data)
            return query_data
        except:
            return None


def load_qep_explanations(tree):
    return tree.explain_all_nodes(tree.root).strip()


def initialize_tree(plan_json, login_details, query_details):
    tree = Tree(login_details, query_details)
    tree.build_tree(plan_json)

    # Explain each node by DFS and return the output
    return tree


class Tree(object):
    """
    Represents a Query Tree generated by PostgreSQL's JSON output

    This tree is binary. If there is only one child, the child node will
    be assigned to the left child.

    @param login_details: User-provided login details to the UI
    @param query_details: Contains the user-selected database and user-input query
    """

    def __init__(self, login_details: LoginDetails, query_details: QueryDetails):
        # Root node of the tree
        self.root = None

        # Stores user-input details
        self.login_details = login_details
        self.query_details = query_details

        # The output string for the entire query tree that will be printed on the interface
        self.full_output = ""

        # Keeps track at tree-level the value of n
        # for the n-th node that is currently being processed
        self.order = 1

    def build_tree(self, node_json):
        """
        Recursively build the binary tree from JSON data
        Data given to build_tree is the value of the key "Plan"

        @param node_json: The JSON / dictionary of details specific to the node
        """

        # Saves the root and begins recursively creating the tree
        self.root = self._build_tree_recursive(node_json, count=[1])

    def _build_tree_recursive(self, node_json, count=[1]):
        """
        Helper function of self.Build_tree()

        Recursively build the binary tree from node data

        @param node_json: The JSON / dictionary of details specific to the node
        @param count: Mutable list which is by reference can maintain the state throughout mutable calls.
        @return: The instantiated node
        """

        # Default case - Previous node is already a leaf node
        if not node_json:
            return None

        # Instantiate a Node subclass
        node = self.instantiate_node(node_json)

        if node:
            node.id = count[0]  # Assign the current count as the node number
            count[0] += 1  # Increment the count for the next node

        # Continue running this function only if there are child nodes
        if node is not None and "Plans" in node.node_json:
            plans = node.node_json["Plans"]
            if len(plans) == 1:
                node.left = self._build_tree_recursive(plans[0], count)
            elif len(plans) == 2:
                node.left = self._build_tree_recursive(plans[0], count)
                node.right = self._build_tree_recursive(plans[1], count)

            # node.node_json["Plans"] no longer needed, empty it to save storage
            node.node_json["Plans"] = {}

        return node

    def explain_all_nodes(self, node):
        """
        Perform depth-first traversal of the query tree to obtain
        the explanations for all of the nodes in the tree

        @param node: Current node to explain.
                     On first call of the function, node = root.
                     Otherwise, node is either node.left or node.right
        @return: The output for the entire tree
        """

        if node is not None:
            self.explain_all_nodes(node.left)
            self.explain_all_nodes(node.right)

            # After calling explain() on both child nodes
            # Merge their parent_dict before processing current node
            node.merge_dict()

            # Define any explanations here after info from children nodes are received
            node.define_explanations()

            # Append the explanation of the node to the full string
            # And add separators to distinguish between different nodes
            self.full_output = self.full_output + node.explain(self.order) + "\n"
            if node is not self.root:
                self.full_output = (
                    self.full_output + "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n"
                )

            # Increment current node order
            self.order += 1

        return self.full_output

    def instantiate_node(self, node_json):
        """
        Checks what is the value of node_json["Node Type"]

        Then, instantiate a Node subclass based on the node type

        @param node_json: The JSON / dictionary of details specific to the node
        @return: An instance of the selected subclass of Node
        """
        match node_json["Node Type"]:
            case "Seq Scan":
                return SeqScanNode(node_json, self.login_details, self.query_details)
            case "Index Scan":
                return IndexScanNode(node_json, self.login_details, self.query_details)
            case "Index Only Scan":
                return IndexOnlyScanNode(
                    node_json, self.login_details, self.query_details
                )
            case "Bitmap Index Scan":
                return BitmapIndexScanNode(
                    node_json, self.login_details, self.query_details
                )
            case "Bitmap Heap Scan":
                return BitmapHeapScanNode(
                    node_json, self.login_details, self.query_details
                )
            case "Bitmap And":
                return BitmapAndNode(node_json, self.login_details, self.query_details)
            case "Bitmap Or":
                return BitmapOrNode(node_json, self.login_details, self.query_details)
            case "CTE Scan":
                return CTEScanNode(node_json, self.login_details, self.query_details)
            case "Subquery Scan":
                return SubqueryScanNode(
                    node_json, self.login_details, self.query_details
                )
            case "Append":
                return AppendNode(node_json, self.login_details, self.query_details)
            case "MergeAppend":
                return MergeAppendNode(
                    node_json, self.login_details, self.query_details
                )
            case "Nested Loop Join":
                return NestedLoopJoinNode(
                    node_json, self.login_details, self.query_details
                )
            case "Merge Join":
                return MergeJoinNode(node_json, self.login_details, self.query_details)
            case "Hash":
                return HashNode(node_json, self.login_details, self.query_details)
            case "Hash Join":
                return HashJoinNode(node_json, self.login_details, self.query_details)
            case "Gather":
                return GatherNode(node_json, self.login_details, self.query_details)
            case "Gather Merge":
                return GatherMergeNode(
                    node_json, self.login_details, self.query_details
                )
            case "Sort":
                return SortNode(node_json, self.login_details, self.query_details)
            case "Incremental Sort":
                return IncrementalSortNode(
                    node_json, self.login_details, self.query_details
                )
            case "Limit":
                return LimitNode(node_json, self.login_details, self.query_details)
            case "Materialize":
                return MaterializeNode(
                    node_json, self.login_details, self.query_details
                )
            case "Memoize":
                return MemoizeNode(node_json, self.login_details, self.query_details)
            case "Group":
                return GroupNode(node_json, self.login_details, self.query_details)
            case "Aggregate":
                return AggregateNode(node_json, self.login_details, self.query_details)
            case "Unique":
                return UniqueNode(node_json, self.login_details, self.query_details)
            case _:
                return Node(node_json, self.login_details, self.query_details)


class Node(object):
    """
    Represents a Node in PostgreSQL's EXPLAIN JSON output

    All nodes should inherit from this class.
    The subclasses should also replace the following attributes
    and functions with their own implementations:
    - __init__(self) to replace str_explain_formula and str_explain_difference
    - manual_cost(node_json)

    @param node_json: The JSON / dictionary of details specific to the node
    @param login_details: User-provided login details to the UI
    @param query_details: Contains the user-selected database and user-input query
    """

    def __init__(self, node_json, login_details, query_details):
        # Stores user-input details
        self.login_details = login_details
        self.query_details = query_details

        # The JSON of this particular node
        self.node_json = node_json

        # Left and right child Node
        self.left = None
        self.right = None

        # The entire output string that will be printed by the interface.
        # This variable should ONLY be modified between when explain() is triggered
        # and when explain() is returned
        self.output = ""

        # Dict data structure to pass to parent
        self.parent_dict = None

        # Id for node for easy reference
        self.id = None

    def define_explanations(self):
        # Given formula or how formula is derived
        self.str_explain_formula = "str_explain_formula"

        # Brief explanation on the difference between formula and system calculations
        self.str_explain_difference = "str_explain_difference"

    def manual_cost(self):
        """
        Run the SQL helper functions here.
        Each SQL helper function will also append a line to the output
        This method will return the total manually calculated cost.

        @returns: An integer for the manually calculated total cost
        """
        return 0

    def explain(self, order=0):
        """
        Prepares the output for the particular node to be printed by the interface.
        Also handles clean-up after explain() is executed successfully

        @type order : int
        @param order : The order in which this Node is being explained, relative
                       to the entire query tree
        """

        # Reset the output just in case
        self.output = ""

        # Briefly introduce the node with the name of the Node Type
        self.append(
            str(order) + ". " + self.node_json["Node Type"] + " (#" + str(self.id) + ")"
        )
        self.append()

        # Append the formula explanation
        self.append(self.str_explain_formula)
        calculated_cost = self.manual_cost()

        # Append the calculated cost
        self.append("Calculated Cost: " + str(calculated_cost))
        self.append()

        # Append the PostgreSQL total cost
        self.append(
            "PostgreSQL Total Cost: " + str(self.node_json.get("Total Cost", "Unknown"))
        )

        # Compare the calculated cost with PostgreSQL's total cost
        if calculated_cost == self.node_json.get("Total Cost"):
            self.append(
                "Manually calculated cost is the same as system calculated cost."
            )
        else:
            self.append(
                "Manually calculated cost is different from system calculated cost."
            )
            self.append()
            self.append("Reason for difference:")
            self.append(self.str_explain_difference)

        # This node has been explained once
        # Build a dict to pass to parent to mark this Node as explained
        self.parent_dict = self.build_parent_dict()

        return self.output

    def build_parent_dict(self):
        """
        Builds a dict of specific values to pass to the parent Node for their
        calculations. Only includes necessary attributes.
        """
        parent_dict = {
            # Node type of current node
            "Node Type": "Placeholder",
            # Estimated number of blocks for the intermediate relation
            # resulting from this node
            "block_size": 0,
            # Estimated number of tuples for the intermediate relation
            # resulting from this node
            "tuple_size": 0,
            # Manually calculated cost of executing this node
            "manual_cost": 0,
            # Given Total Cost by Postgres from executing this node
            "postgre_cost": 0,
        }

        return parent_dict
        # attr: self.node_json[attr] for attr in attributes if attr in self.node_json

    def merge_dict(self):
        """
        Obtains the dictionary created by the left and right childs if any
        Then, label the dict to each child, and merge the two dictionaries
        with the JSON provided by PostgreSQL into one big dictionary.
        """
        if self.left is not None:
            for key, value in self.left.parent_dict.items():
                self.node_json["Left " + key] = value
        if self.right is not None:
            for key, value in self.right.parent_dict.items():
                self.node_json["Right " + key] = value

    def append(self, tgt: str = "", src: str = "output", eol: str = "\n"):
        """
        Append a string to the end of the selected string.
        If no src is specified, then append to Node.output
        If no tgt is specified, then the behaviour is similar to print(),
        which is to add an empty line to the output
        If no eol is specified, a newline character will be added after each string.

        @param tgt: The string to append to at the end of the source string
        @param src: Specifies which string to append the target string to.
                    If append to self.str_explain_formula, src = "formula"
                    If append to self.str_explain_difference, src = "difference"
                    Otherwise, append to self.output
        @param eol: End-of-line. Append additionally this character or string to the end of the target string
        """

        match src:
            case "formula":
                self.str_explain_formula = self.str_explain_formula + tgt + eol
            case "difference":
                self.str_explain_difference = self.str_explain_difference + tgt + eol
            case _:
                self.output = self.output + tgt + eol

    ######### Functions that Re-queries the Database #########

    def B(self, relation: str, show: bool = True):
        """
        Return number of blocks for the specified relation

        @param relation : The relation to query
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = """
        SELECT pg_relation_size('{rel}') / current_setting('block_size')::int AS num_blocks
        """.format(
            rel=relation
        )

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_blocks = result[0][0]

        if show:
            self.append(
                "Number of blocks for relation '" + relation + "': " + str(num_blocks)
            )
        return num_blocks

    def T(self, relation: str, show: bool = True):
        """
        Return number of tuples for the specified relation

        @param relation : The relation to query
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = """
        SELECT COUNT(*) as num_tuples FROM {rel}
        """.format(
            rel=relation
        )

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_tuples = result[0][0]

        if show:
            self.append(
                "Number of tuples for relation '" + relation + "': " + str(num_tuples)
            )
        return num_tuples

    def M(self, show: bool = True):
        """
        Return buffer size allocated to DBMS in memory

        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = """
        SELECT setting FROM pg_settings WHERE name = 'shared_buffers';
        """

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        buffer_size = int(result[0][0])

        if show:
            self.append("Buffer size: " + str(buffer_size))
        return buffer_size

    def V(self, relation: str, attribute: str, show: bool = True):
        """
        Return number of unique values for the attribute in
        the provided relation

        @param relation : The relation to query
        @param attribute : The attribute of the relation to query
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = """
        SELECT COUNT(DISTINCT {attr}) AS num_unique_values FROM {rel};
        """.format(
            attr=attribute, rel=relation
        )

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_unique = result[0][0]

        if show:
            self.append(
                "Number of unique values for attribute '"
                + attribute
                + "' of relation '"
                + relation
                + "': "
                + str(num_unique)
            )
        return num_unique


#################### NODE SUBCLASSES ######################


class MyNode(Node):
    """
    Testing node. Will print all of B(), T(), V() and M
    """

    def define_explanations(self):
        self.str_explain_formula = "Formula: B(rel) + T(rel) + V(rel, attr) + M"
        self.str_explain_difference = "Some explanation for difference"

    def manual_cost(self):
        rel = "nation"
        attr = "n_name"
        return self.B(rel) + self.T(rel) + self.V(rel, attr) + self.M()

    def build_parent_dict(self):
        rel = "nation"

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": 10,
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class ScanNodes(Node):
    """
    Helper class that contains utility functions for most scan-related nodes
    """

    def cardinality(self, is_tuple):
        """
        Estimate number of filtered tuple resulting from this query node

        @param is_tuple: True if returning number of tuples. False if returning number of blocks
        """

        # Preliminary calculations
        rel = self.node_json["Relation Name"]
        num_blocks = self.B(rel, False)
        num_tuples = self.T(rel, False)

        # Count number of conditions in the filter
        count_cond = self.count_conditions()

        # Three different cases
        if "Filter" or "Index Cond" not in self.node_json:
            # Case 1: Retrieve entire table. Selectivity = 1
            return num_tuples if is_tuple else num_blocks

        # Calculate selectivity for each condition
        num_return = num_tuples if is_tuple else num_blocks
        for i in range(count_cond):
            attr = self.retrieve_attribute_from_condition(i)
            op = self.retrieve_operator_from_condition(i)
            num_unique = self.V(rel, attr, False)

            if ">" or "<" in op:
                # Case 2: Retrieve a range of records. Selectivity = 1/3
                selectivity = 1 / 3

            else:
                # Case 3: Retrieve one exact record. Selectivity = V(R, a)
                if num_unique == 0:
                    selectivity = 0
                selectivity = 1 / num_unique

            # Multiply selectivity into num_return
            num_return *= selectivity

    def count_conditions(self):
        """
        Determine the number of conditions embedded in the filter

        @return An integer specifying the number of conditions. If "Filter" is not present, return 0
        """

        # Retrieve the filter from node_json
        if "Filter" in self.node_json:
            filter = self.node_json["Filter"]
        elif "Index Cond" in self.node_json:
            filter = self.node_json["Index Cond"]
        else:
            return 0

        # Count the occurrences of 'AND' to determine the number of conditions
        return filter.count("AND") + 1

    def retrieve_attribute_from_condition(self, cond_index=0):
        """
        Pass in the value from node_json["Filter"] or node_json["Index Cond"] and return the attribute
        Example filter = "(o_custkey < 1000000)" returns "o_custkey"

        @param cond_index: Condition index. For filters with more than one condition,
                           specify which condition to extract the attribute from.
                           Condition index starts from 0
        """

        # Retrieve the filter from node_json
        if "Filter" in self.node_json:
            filter = self.node_json["Filter"]
        elif "Index Cond" in self.node_json:
            filter = self.node_json["Index Cond"]
        else:
            return

        # Find the condition within parentheses using split
        conditions = filter.split("AND")

        # Extract the specified condition and remove the brackets
        specified_condition = conditions[cond_index].strip().strip("()")

        # Find the index of the comparison operator
        comparison_operators = ["<", ">", "="]
        index = min(
            specified_condition.find(op)
            for op in comparison_operators
            if op in specified_condition
        )

        # Extract the text before the comparison operator
        text_before_operator = specified_condition[:index].strip()

        # Extract the attribute name from the text before the comparison operator
        attr = text_before_operator.split(".")[-1]

        return attr

    def retrieve_operator_from_condition(self, cond_index=0):
        """
        Pass in the value from node_json["Filter"] or node_json["Index Cond"] and return the attribute
        Example filter = "(o_custkey < 1000000)" returns '<'

        @param cond_index: Condition index. For filters with more than one condition,
                           specify which condition to extract the attribute from.
                           Condition index starts from 0
        """

        # Find the condition within parentheses using split
        conditions = filter.split("AND")

        # Extract the specified condition and strip opening and closing brackets
        specified_condition = conditions[cond_index - 1].strip().strip("()")

        # Find the index of the comparison operator
        comparison_operators = ["<", ">", "=", "<=", ">="]
        index = min(
            specified_condition.find(op)
            for op in comparison_operators
            if op in specified_condition
        )

        # Extract the comparison operator
        operator = specified_condition[index:].split()[0]

        # Map <= and >= to < and >
        if operator == "<=":
            operator = "<"
        elif operator == ">=":
            operator = ">"

        return operator

    def build_parent_dict(self):
        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.cardinality(False),
            "tuple_size": self.cardinality(True),
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class SeqScanNode(ScanNodes):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        rel = self.node_json["Relation Name"]
        self.append(src="formula", tgt="Sequential scan on relation '" + rel + "'")
        self.append(src="formula", tgt="Cost Formula: B(" + rel + ")")

        # Explain the difference
        self.append(
            src="difference",
            tgt="PostgreSQL estimates the selectivity more accurately.",
        )
        self.append(
            src="difference",
            tgt="PostgreSQL factors in parallel processing and CPU cost into the calculation",
        )

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        return self.B(rel)

    def build_parent_dict(self):
        # All other values are unchanged
        parent_dict = super().build_parent_dict()

        # Except for manual_cost
        rel = self.node_json["Relation Name"]
        parent_dict["manual_cost"] = self.B(rel, False)

        return parent_dict


class IndexScanNode(ScanNodes):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        self.append(
            src="formula",
            tgt="Index on attribute '" + attr + "' of relation '" + rel + "'",
        )
        self.append(
            src="formula",
            tgt="Cost Formula: T(" + rel + ") / V(" + rel + ", " + attr + ")",
        )

        # Explain the difference
        self.append(
            src="difference",
            tgt="PostgreSQL uses the more accurate Market and Lohman approximation to estimate number of pages fetched.",
        )
        self.append(
            src="difference",
            tgt="Also, PostgreSQL uses optimizations such as parallel processing and caching.",
        )
        self.append(
            src="difference",
            tgt="These will either reduce cost or makes cost computation more accurate.",
        )

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        return self.T(rel) / self.V(rel, attr)

    def build_parent_dict(self):
        # All other values are unchanged
        parent_dict = super().build_parent_dict()

        # Except for manual_cost
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        parent_dict["manual_cost"] = self.T(rel, False) / self.V(rel, attr, False)

        return parent_dict


class IndexOnlyScanNode(ScanNodes):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        self.append(
            src="formula",
            tgt="Index on attribute '" + attr + "' of relation '" + rel + "'",
        )
        self.append(
            src="formula",
            tgt="Cost Formula: T(" + rel + ") / V(" + rel + ", " + attr + ")",
        )

        # Explain the difference
        self.str_explain_difference = """Index Only Scan differs from Index Scan in that PostgreSQL only needs to access the index blocks as all of the values required are in the index.
        PostgreSQL uses methods to reduce the cost as a result of not requiring to access heap storage.
        """

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        return self.T(rel) / self.V(rel, attr)

    def build_parent_dict(self):
        # All other values are unchanged
        parent_dict = super().build_parent_dict()

        # Except for manual_cost
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        parent_dict["manual_cost"] = self.T(rel, False) / self.V(rel, attr, False)

        return parent_dict


class BitmapIndexScanNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        self.str_explain_formula = (
            "As PostgreSQL does not access the data blocks, the cost is negligible"
        )
        self.str_explain_difference = """PostgreSQL factors in the cost of accessing the index blocks of the relation"""

    def manual_cost(self):
        return 0

    def build_parent_dict(self):
        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class BitmapHeapScanNode(ScanNodes):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        self.append(
            src="formula",
            tgt="Accessing the heap through index on attribute '"
            + attr
            + "' of relation '"
            + rel
            + "'",
        )
        self.append(
            src="formula",
            tgt="Cost Formula: T(" + rel + ") / V(" + rel + ", " + attr + ")",
        )

        # Explain the difference
        self.str_explain_difference = """PostgreSQL factors in overhead of bitmap access into cost calculation
        """

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        return self.T(rel) / self.V(rel, attr)

    def build_parent_dict(self):
        # All other values are unchanged
        parent_dict = super().build_parent_dict()

        # Except for manual_cost
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_condition()
        parent_dict["manual_cost"] = self.T(rel, False) / self.V(rel, attr, False)

        return parent_dict


class BitmapAndNode(Node):
    def define_explanations(self):
        self.str_explain_formula = "AND operation on bit arrays are negligible"
        self.str_explain_difference = (
            """PostgreSQL factors in overhead of bitmap access into cost calculation"""
        )

    def manual_cost(self):
        return 0

    def build_parent_dict(self):
        rel = self.node_json["Relation Name"]

        # Treat this as an intersect operator unless there is more time
        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": min(
                self.node_json["Left block_size"], self.node_json["Right block_size"]
            ),
            "tuple_size": min(
                self.node_json["Left tuple_size"], self.node_json["Right tuple_size"]
            ),
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class BitmapOrNode(Node):
    def define_explanations(self):
        self.str_explain_formula = "OR operation on bit arrays are negligible"
        self.str_explain_difference = """PostgreSQL factors in overhead of bitmap access into cost calculation
        """

    def manual_cost(self):
        return 0

    def build_parent_dict(self):
        rel = self.node_json["Relation Name"]

        # Treat this as a union operator unless there is more time
        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.node_json["Left block_size"]
            + self.node_json["Right block_size"],
            "tuple_size": self.node_json["Left tuple_size"]
            + self.node_json["Right tuple_size"],
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class CTEScanNode(SeqScanNode):
    """
    CTE Scan is very similar to sequential scan, but for WITH operations
    """

    pass


class SubqueryScanNode(SeqScanNode):
    """
    Subquery Scan is very similar to sequential scan, but for nested SELECT operations
    """

    pass


class AppendNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        self.append(src="formula", tgt="Combine the results of the child operations.")
        self.append(src="formula", tgt="Cost Formula: SIGMA(Cost(Child))")

        # Explain the difference
        self.append(
            src="difference",
            tgt="PostgreSQL's implementation of cost calculation takes the sum of startup cost and run cost of subpath operations, which is much more complex when compared to our assumptions.",
        )

    def manual_cost(self):
        total_cost = self.node_json["Left manual_cost"]
        if self.right is not None:
            total_cost += self.node_json["Right manual_cost"]

        return total_cost

    def build_parent_dict(self):

        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": self.manual_cost(),
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class MergeAppendNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        self.append(
            src="formula",
            tgt="Combines the sorted results of the child operations, in a way that preserves their sort order.",
        )
        self.append(
            src="formula",
            tgt="Cost Formula: SIGMA(Cost(Child)) + Merge_Cost",
        )

        # Explain the difference
        self.append(
            src="difference",
            tgt="MergeAppend of PostgreSQL merges several pre-sorted input streams, using a heap that at any given instant holds the next tuple from each stream.  If there are N streams, we need about N*log2(N) tuple comparisons to construct the heap at startup, and then for each output tuple, about log2(N) comparisons to replace the top entry.",
        )

    def manual_cost(self):
        total_cost = self.node_json["Left manual_cost"]
        if self.right is not None:
            total_cost += self.node_json["Right manual_cost"]

        # Merge cost might be proportional to the total number of rows across all children
        # Assuming a linear merge cost model here
        merge_cost = self.node_json["Left tuple_size"]
        if self.right is not None:
            merge_cost += self.node_json["Right tuple_size"]

        total_cost += merge_cost

        return total_cost

    def build_parent_dict(self):

        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": self.manual_cost(),
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class NestedLoopJoinNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        # Explain the relation, attribute
        self.append(
            src="formula",
            tgt="An implementation of join or lookup where the first child node is run once, then for every row it produces, its partner is looked up in the second node.",
        )
        self.append(
            src="formula",
            tgt="min(B("
            + rel_R
            + "), B("
            + rel_S
            + ")) + (B("
            + rel_R
            + ") * B("
            + rel_S
            + "))",
        )

        # Explain the difference
        self.append(
            src="difference",
            tgt="The cost estimation in PostgreSQL sums up the startup cost, total cost of both outer and inner path, and also the rescan cost of the inner path.",
        )
        self.append(
            src="difference",
            tgt="However, the approach is different and not by using block size, but instead it takes the cost of the path.",
        )

    def manual_cost(self):

        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return min(R_block_size, S_block_size) + (R_block_size * S_block_size)

    def build_parent_dict(self):

        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": self.manual_cost(),
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class MergeJoinNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        # Explain the relation, attribute
        self.append(
            src="formula",
            tgt="An implementation of join which is possible when the two lists of rows to be joined are already sorted on their join keys.",
        )
        self.append(
            src="formula",
            tgt="3(B(" + rel_R + ") + B(" + rel_S + "))",
        )

        # Explain the difference
        self.append(
            src="difference",
            tgt="PostgreSQL's cost estimation is more comprehensive, accounting for sorting costs, actual data size and distribution, and system factors like disk I/O, CPU usage, and caching effects, leading to a more accurate and context-sensitive prediction.",
        )

    def manual_cost(self):

        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return 3 * (R_block_size + S_block_size)

    def build_parent_dict(self):

        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": self.manual_cost(),
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class HashNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        self.append(
            src="formula",
            tgt="Hashes the query rows for use by its parent operation, usually used to perform a JOIN.",
        )
        self.append(
            src="formula",
            tgt="We assume the cost are calculated in the hash join node, thus ignore the cost here.",
        )

        # Explain the difference
        self.append(
            src="difference",
            tgt="We assume the cost are calculated in the hash join node, thus ignore the cost here.",
        )
        self.append(
            src="difference",
            tgt="In PostgreSQL, the cost is calculated for the whole hash join process using two versions of estimation function, no separate calculation for hash nodes.",
        )

    def manual_cost(self):

        # return self.node_json["Left tuple_size"]

        return 0

    def build_parent_dict(self):

        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class HashJoinNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        # Explain the relation, attribute
        self.append(
            src="formula",
            tgt="A hash join operation between two relations, where the first relation "
            + rel_R
            + " is used to build the hash table, and the second relation "
            + rel_S
            + " is then probed against this hash table.",
        )
        self.append(
            src="formula",
            tgt="3(B(" + rel_R + ") + B(" + rel_S + "))",
        )

        # Explain the difference
        self.append(
            src="difference",
            tgt="Our implementation here follows the Grace hash join calculation.",
        )
        self.append(
            src="difference",
            tgt="PostgreSQL does not use the Grace hash join algorithm. ",
        )
        self.append(
            src="difference",
            tgt="Instead, it implements a variant of the hash join that is optimized for in-memory operations but can also handle larger-than-memory datasets by spilling to disk.",
        )

    def manual_cost(self):
        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return 3 * (R_block_size * S_block_size)

    def build_parent_dict(self):

        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": self.manual_cost(),
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class GatherNode(Node):  # formula unsure
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        self.append(
            src="formula",
            tgt="Combines the output of child nodes, which are executed by parallel workers.",
        )
        self.append(src="formula", tgt="Cost Formula: SIGMA(Cost(Child))")

        # Explain the difference
        self.append(
            src="difference",
            tgt="PostgreSQL's implementation of cost calculation takes the sum of startup cost and run cost of subpath operations, which is much more complex when compared to our assumptions. Parallel setup and communication cost are also taken into consideration.",
        )

    def manual_cost(self):
        total_cost = self.node_json["Left manual_cost"]
        if self.right is not None:
            total_cost += self.node_json["Right manual_cost"]

        return total_cost

    def build_parent_dict(self):

        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": self.manual_cost(),
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class GatherMergeNode(Node):  # formula unsure
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        self.append(
            src="formula",
            tgt="Combines the output of child nodes, which are executed by parallel workers. Gather Merge consumes sorted data, and preserves this sort order.",
        )
        self.append(
            src="formula",
            tgt="Cost Formula: SIGMA(Cost(Child)) + Merge_Cost",
        )

        # Explain the difference
        self.append(
            src="difference",
            tgt="GatherMerge of PostgreSQL merges several pre-sorted input streams, using a heap that at any given instant holds the next tuple from each stream. If there are N streams, we need about N*log2(N) tuple comparisons to construct the heap at startup, and then for each output tuple, about log2(N) comparisons to replace the top heap entry with the next tuple from the same stream. Parallel setup  and communication cost are also taken into consideration.",
        )

    def manual_cost(self):
        total_cost = self.node_json["Left manual_cost"]
        if self.right is not None:
            total_cost += self.node_json["Right manual_cost"]

        # Merge cost might be proportional to the total number of rows across all children
        # Assuming a linear merge cost model here
        merge_cost = self.node_json["Left tuple_size"]
        if self.right is not None:
            merge_cost += self.node_json["Right tuple_size"]

        total_cost += merge_cost

        return total_cost

    def build_parent_dict(self):

        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": self.manual_cost(),
            "postgre_cost": self.node_json["Total Cost"],
        }

        return parent_dict


class SortGroupNodes(Node):
    def extract_relation_name(self):
        """
        Retrieve the name of the relation from node_json["Sort Key"] or node_json["Group Key"]
        """

        # Retrieve the value from node_json
        if "Sort Key" in self.node_json:
            key = self.node_json["Sort Key"][0]
        elif "Group Key" in self.node_json:
            key = self.node_json["Group Key"][0]

        # Split the key string by dot (.) to separate the relation name
        parts = key.split(".")
        if len(parts) > 1:
            # Return the first part as the relation name
            return parts[0]
        else:
            # If the key does not contain a dot, return None
            return None


class SortNode(SortGroupNodes):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""
        
        # explain relation and attributes

        if self.node_json["Sort Method"] == "external merge":
            self.append(src="formula", tgt="Mergesort Formula : 3 * B(rel)")
            self.append(
                src="formula",
                tgt="Mergesort is used when data does not fit in memory(work_mem)",
            )
            self.append(src="formula", tgt="Plan width * T(R) > work_mem")
            self.append(
                src="difference",
                tgt="PostgreSQL includes default cost per comparison costs and overhead per extracted tuple",
            )

        elif self.node_json["Sort Method"] == "quicksort":
            self.append(
                src="formula",
                tgt="Quicksort Formula : B(rel). This is the default algorithm",
            )
            self.append(
                src="formula",
                tgt="Quicksort is used when entire data fits into memory(work_mem) -- One pass.",
            )
            self.append(src="formula", tgt="Plan width * T(R) < work_mem")
            self.append(
                src="difference",
                tgt="PostgreSQL includes default cost per comparison costs and overhead per extracted tuple",
            )

        elif self.node_json["Sort Method"] == "top-N heapsort":
            self.append(src="formula", tgt="Top-N heapsort Formula : B(rel) / 3.")
            self.append(
                src="formula",
                tgt="Top-N heapsort is used when only a limited amount of data is required, such as when theres LIMIT after order.",
            )
            self.append(
                src="difference",
                tgt="PostgreSQL includes default cost per comparison costs and overhead per extracted tuple, as well as cost to maintain heap of the top N items.",
            )

    def manual_cost(self):
        rel = super().extract_relation_name()
        if self.node_json["Sort Method"] == "external merge":
            return self.B(rel) * 3

        elif self.node_json["Sort Method"] == "quicksort":
            return self.B(rel)

        elif self.node_json["Sort Method"] == "top-N heapsort":
            # Not sure about topn cost
            return self.B(rel) / 3


class IncrementalSortNode(SortGroupNodes):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # explain relation and attributes
        self.append(src="formula", tgt="Formula : B(rel) - Estimated Sorted Blocks.")
        self.append(
            src="formula",
            tgt="Incremental Sort is used when input data is partially ordered",
        )
        self.append(
            src="difference",
            tgt="Postgresql uses different calculations to calculate number of groups with equal presorted keys.",
        )
        self.append(
            src="difference",
            tgt="There are also overhead costs in detecting sort groups and additional costs for each input group.",
        )

    def manual_cost(self):
        rel = super().extract_relation_name()
        return self.B(rel) / 3


class LimitNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""
        
        # explain relation and attributes
        self.str_explain_formula = "Formula : B(rel) * "
        self.str_explain_difference = """Explain """

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        return self.B(rel)


class MaterializeNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # explain relation and attributes
        self.append(src="formula", tgt="Materialize Formula : T(rel) * 2")
        self.append(
            src="formula",
            tgt="Materialize is used to store intermediate results temporarily to improve efficiency",
        )
        self.append(
            src="difference",
            tgt="PostgreSQL includes cpu operator costs per tuple to reflect bookkeeping overhead.",
        )
        self.append(
            src="difference",
            tgt="PostgreSQL also accounts for when volume of data to materialize exceeds work_mem and needs to be written to disk(higher cost)",
        )

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        return self.T(rel) * 2


class MemoizeNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # explain relation and attributes
        self.append(
            src="formula",
            tgt="Memoize used to cache and reuse results of expensive operations when they are executed with the same parameters multiple times in a query.",
        )
        self.append(
            src="formula",
            tgt="Since the previous query used it, there is no cost involved in fetching it from memory again.",
        )
        self.str_explain_difference = """Costs of a memoize node dependent also on nature of operations and frequency, cache hit rate and lookup times  """

    def manual_cost(self):
        return 0


class GroupNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        self.str_explain_formula = "Formula : T(rel) * Number of Group Columns. "
        self.str_explain_difference = """PostgreSQL includes default cost per comparison costs overhead per input tuple.  """

    def manual_cost(self):
        # test if can
        rel = self.node_json["Relation Name"]
        numGroupCol = len(self.node_json.get("Group Key", []))
        return self.T(rel) * numGroupCol


class AggregateNode(SortGroupNodes):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        if (
            self.node_json["Strategy"] == "Sorted"
            or self.node_json["Strategy"] == "Mixed"
        ):
            self.str_explain_formula = "Formula : T(rel) * Number of groups. Aggregate used to compute summaries from sets of values like SUM,AVG. "
            self.str_explain_difference = """PostgreSQL has different aggregate strategies depending on the input.  """

        # assume T(rel) as cost
        elif self.node_json["Strategy"] == "Hashed":
            self.str_explain_formula = "Formula : T(rel). Aggregate hash strategy used over all rows when there is no group by"
            self.str_explain_difference = """Aggregate Hash costs include computing hash value and retiving from hash table, and cost due to chance of tuple spilling.  """

        # default, Agg strategy is plain
        else:
            self.str_explain_formula = "Formula : T(rel). Aggregate plain strategy used over all rows when there is no group by, no need for grouping before aggregation"
            self.str_explain_difference = """PostgreSQL includes default cost per comparison costs overhead per input tuple.  """

    def manual_cost(self):
        rel = super().extract_relation_name()
        if (
            self.node_json["Strategy"] == "Sorted"
            or self.node_json["Strategy"] == "Mixed"
        ):
            numGroupCol = len(self.node_json.get("Group Key", []))
            return self.T(rel) * numGroupCol

        else:
            return self.T(rel)


class UniqueNode(Node):
    def define_explanations(self):
        self.str_explain_formula = ""
        self.str_explain_difference = ""
        self.str_explain_formula = "Remove duplicates from sorted set"

    def manual_cost(self):
        return 0
